Base:
    model_root: './checkpoints/'
    num_workers: 3
    verbose: 1
    early_stop_patience: 2
    pickle_feature_encoder: True
    save_best_only: True
    eval_steps: null
    debug_mode: False
    group_id: null
    use_features: null
    feature_specs: null
    feature_config: null

APG_AITMV2_test:
    model: APG_AITMV2
    dataset_id: all_seeds_processed
    loss: [binary_crossentropy, binary_crossentropy, binary_crossentropy]
    metrics: [AUC, KS, recall, precision, f1]
    task: [binary_classification, binary_classification, binary_classification]
    num_tasks: 3
    optimizer: adam
    learning_rate: 1.e-3
    embedding_regularizer: 1.e-8
    net_regularizer: 0
    batch_size: 8192
    embedding_dim: 4
    hidden_activations: relu
    net_dropout: 0
    batch_norm: False
    epochs: 10
    shuffle: True
    seed: 2019
    monitor: AUC
    monitor_mode: max
    verbose: 1

    # APG condition
    condition_mode: "group-wise"  # self-wise, group-wise, mix-wise
    condition_features: ['product']
    condition_participate_bottom: True
    rank_k: 16
    overparam_p: 64
    hypernet_config:
        hidden_units: [32]
        hidden_activations: relu

    # PLE/CGC bottom
    num_layers: 1
    num_shared_experts: 2
    num_specific_experts: 2
    expert_hidden_units: [64, 64]
    gate_hidden_units: [64]

    # Cascaded transfer (funnel-friendly)
    transfer_type: gated_residual  # gated_residual | attn
    transfer_gate_hidden_units: [64]
    use_prev_logit: True
    detach_prev_rep: True
    detach_prev_logit: True

    # Tower
    tower_type: dnn  # dnn | apg
    tower_hidden_units: [32, 32]
