import streamlit as st
import os
import subprocess
import sys
import time
import signal
import pandas as pd
import yaml
import shutil
import json
import base64

# Set page config
st.set_page_config(
    page_title="FuxiCTR å®éªŒå¹³å°",
    page_icon="ğŸ­",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize Session State
if "run_pid" not in st.session_state:
    st.session_state.run_pid = None
if "run_logfile" not in st.session_state:
    st.session_state.run_logfile = None
if "running_model" not in st.session_state:
    st.session_state.running_model = None
if "show_tutorial" not in st.session_state:
    st.session_state.show_tutorial = False

# Custom CSS for better UI
st.markdown("""
<style>
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    h1 {
        color: #1E3A8A; /* Dark Blue */
        font-weight: 700;
    }
    h2 {
        color: #1F2937;
        border-bottom: 2px solid #E5E7EB;
        padding-bottom: 0.5rem;
        margin-top: 1rem;
    }
    h3 {
        color: #4B5563;
        font-size: 1.1rem;
    }
    .stButton>button {
        width: 100%;
        border-radius: 8px;
        font-weight: 600;
    }
    .stSelectbox label {
        font-weight: 600;
        color: #374151;
    }
    /* Sidebar styling */
    [data-testid="stSidebar"] {
        background-color: #F3F4F6;
        border-right: 1px solid #E5E7EB;
    }
    /* Card-like containers */
    .css-1r6slb0 {
        border: 1px solid #E5E7EB;
        border-radius: 10px;
        padding: 20px;
        box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.1);
    }
    
    /* Exquisite Button Styling */
    .stButton > button {
        border-radius: 8px;
        height: auto;
        padding: 0.5em 1em;
        font-weight: 600;
        transition: all 0.3s ease;
        border: 1px solid transparent;
    }
    
    /* Primary Button (Start Training) - Gradient */
    .stButton > button[kind="primary"] {
        background: linear-gradient(135deg, #4F46E5 0%, #7C3AED 100%);
        color: white;
        box-shadow: 0 4px 6px -1px rgba(124, 58, 237, 0.3);
        border: none;
    }
    .stButton > button[kind="primary"]:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 12px -1px rgba(124, 58, 237, 0.4);
    }
    
    /* Secondary Button & Download Button - Light Blue Style */
    .stButton > button[kind="secondary"], .stDownloadButton > button[kind="secondary"] {
        background-color: #EFF6FF;
        color: #2563EB;
        border: 1px solid #BFDBFE;
        box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
        width: 100%;
    }
    .stButton > button[kind="secondary"]:hover, .stDownloadButton > button[kind="secondary"]:hover {
        background-color: #DBEAFE;
        color: #1D4ED8;
        border-color: #93C5FD;
        transform: translateY(-1px);
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    
    /* Custom Download Button */
    .custom-download-btn {
        display: inline-flex;
        align-items: center;
        justify-content: center;
        padding: 0.5em 1em;
        background-color: #EFF6FF;
        color: #2563EB;
        border-radius: 8px;
        text-decoration: none;
        font-size: 1rem;
        border: 1px solid #BFDBFE;
        font-weight: 600;
        transition: all 0.2s ease;
        margin-left: 0px;
        vertical-align: middle;
        line-height: 1.6;
    }
    .custom-download-btn:hover {
        background-color: #DBEAFE;
        color: #1D4ED8;
        border-color: #93C5FD;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        text-decoration: none;
    }
</style>
""", unsafe_allow_html=True)

# Paths
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
MODEL_ZOO_DIR = os.path.join(ROOT_DIR, "model_zoo")
DATA_DIR = os.path.join(ROOT_DIR, "data")
LOG_DIR = os.path.join(ROOT_DIR, "dashboard", "logs")
TASK_STATE_DIR = os.path.join(ROOT_DIR, "dashboard", "state", "tasks")
USER_CONFIG_DIR = os.path.join(ROOT_DIR, "dashboard", "user_configs")
os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs(TASK_STATE_DIR, exist_ok=True)
os.makedirs(USER_CONFIG_DIR, exist_ok=True)

# --- Task Management Helpers ---
def cleanup_stale_tasks():
    """Remove task files for processes that are no longer running."""
    if not os.path.exists(TASK_STATE_DIR):
        return
    for f in os.listdir(TASK_STATE_DIR):
        if not f.endswith(".json"): continue
        fpath = os.path.join(TASK_STATE_DIR, f)
        try:
            with open(fpath, 'r') as file:
                data = json.load(file)
            pid = data.get('pid')
            try:
                os.kill(pid, 0) # Check if process exists
            except OSError:
                os.remove(fpath) # Process dead
        except Exception:
            try:
                os.remove(fpath) # Corrupt file
            except:
                pass

def get_active_tasks():
    """Get list of all active tasks."""
    cleanup_stale_tasks()
    tasks = []
    if os.path.exists(TASK_STATE_DIR):
        for f in os.listdir(TASK_STATE_DIR):
            if f.endswith(".json"):
                try:
                    with open(os.path.join(TASK_STATE_DIR, f), 'r') as file:
                        tasks.append(json.load(file))
                except:
                    pass
    return tasks

def save_task_state(username, pid, model, logfile):
    """Register a new task."""
    data = {
        "username": username,
        "pid": pid,
        "model": model,
        "logfile": logfile,
        "start_time": time.time()
    }
    # Filename includes username and pid to be unique
    fpath = os.path.join(TASK_STATE_DIR, f"{username}_{pid}.json")
    with open(fpath, 'w') as f:
        json.dump(data, f)

def remove_task_state(pid):
    """Unregister a task."""
    if not os.path.exists(TASK_STATE_DIR):
        return
    for f in os.listdir(TASK_STATE_DIR):
        if f"_{pid}.json" in f: # Match suffix to be safe
            try:
                os.remove(os.path.join(TASK_STATE_DIR, f))
            except:
                pass

def get_subdirectories(directory):
    if not os.path.exists(directory):
        return []
    return sorted([d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d)) and not d.startswith("__") and not d.startswith(".")])

def get_models(root_dir):
    models = []
    if not os.path.exists(root_dir):
        return []
    
    # First level
    for d in os.listdir(root_dir):
        path = os.path.join(root_dir, d)
        if os.path.isdir(path) and not d.startswith(".") and not d.startswith("__"):
            # Check if it is a model directory (has run_expid.py)
            if os.path.exists(os.path.join(path, "run_expid.py")):
                models.append(d)
            # Check if it is a container like 'multitask'
            else:
                # Check subdirectories
                for sub_d in os.listdir(path):
                    sub_path = os.path.join(path, sub_d)
                    if os.path.isdir(sub_path) and not sub_d.startswith(".") and not sub_d.startswith("__"):
                        if os.path.exists(os.path.join(sub_path, "run_expid.py")):
                            models.append(f"{d}/{sub_d}")
    return sorted(models)

def load_file_content(file_path):
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    return ""

def save_file_content(file_path, content):
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(content)

def get_config_paths(model_name, username):
    """
    Return the effective paths for config files and scripts.
    Priority: User Config > Default Model Config
    """
    model_dir = os.path.join(MODEL_ZOO_DIR, model_name)
    default_config_dir = os.path.join(model_dir, "config")
    user_config_dir = os.path.join(USER_CONFIG_DIR, username, model_name)
    
    # Define files and their default locations
    file_specs = {
        "dataset_config.yaml": os.path.join(default_config_dir, "dataset_config.yaml"),
        "model_config.yaml": os.path.join(default_config_dir, "model_config.yaml"),
        "run_expid.py": os.path.join(model_dir, "run_expid.py")
    }
    
    paths = {}
    
    for filename, default_path in file_specs.items():
        user_path = os.path.join(user_config_dir, filename)
        
        if os.path.exists(user_path):
            paths[filename] = {"path": user_path, "type": "custom", "default_path": default_path}
        else:
            paths[filename] = {"path": default_path, "type": "default", "default_path": default_path}
            
    return paths, user_config_dir

def reset_user_config(username, model_name, filename):
    """Delete user custom config to revert to default."""
    user_path = os.path.join(USER_CONFIG_DIR, username, model_name, filename)
    if os.path.exists(user_path):
        os.remove(user_path)

def get_download_link(content, filename, label):
    """Generate a styled download link."""
    b64 = base64.b64encode(content.encode()).decode()
    return f'<a href="data:application/octet-stream;base64,{b64}" download="{filename}" class="custom-download-btn">â¬‡ï¸ {label}</a>'

# --- Tutorial Page ---
def render_tutorial():
    st.title("ğŸ“š FuxiCTR å¹³å°ä½¿ç”¨æŒ‡å—")
    
    if st.button("ğŸ”™ è¿”å›ä¸»é¡µ"):
        st.session_state.show_tutorial = False
        st.rerun()
        
    st.markdown("---")
    
    st.markdown("""
    ## 1. å¹³å°ç®€ä»‹
    FuxiCTR æ˜¯ä¸€ä¸ªå¯é…ç½®ã€æ¨¡å—åŒ–ã€é«˜æ€§èƒ½çš„ CTR é¢„ä¼°åº“ã€‚æœ¬å¹³å°ï¼ˆFuxiCTR Studioï¼‰æä¾›äº†ä¸€ä¸ªå¯è§†åŒ–çš„ç•Œé¢ï¼Œç”¨äºç®¡ç†å®éªŒã€é…ç½®å‚æ•°ã€ç›‘æ§ä»»åŠ¡å’Œåˆ†æç»“æœã€‚
    
    ## 2. å¿«é€Ÿå…¥é—¨ (App ä½¿ç”¨æµç¨‹)
    
    ### ç¬¬ä¸€æ­¥ï¼šèº«ä»½è®¾ç½®
    åœ¨å·¦ä¾§è¾¹æ çš„ **"ç”¨æˆ·èº«ä»½"** åŒºåŸŸè¾“å…¥æ‚¨çš„ç”¨æˆ·åã€‚
    *   **ä½œç”¨**ï¼šç”¨äºåŒºåˆ†ä¸åŒç”¨æˆ·çš„ä»»åŠ¡ï¼Œé˜²æ­¢æ—¥å¿—å†²çªï¼Œå¹¶è¿›è¡Œèµ„æºé…é¢ç®¡ç†ï¼ˆæ¯äººåŒæ—¶é™è·‘ 1 ä¸ªä»»åŠ¡ï¼‰ã€‚
    
    ### ç¬¬äºŒæ­¥ï¼šé€‰æ‹©æ¨¡å‹
    åœ¨å·¦ä¾§è¾¹æ é€‰æ‹©æ‚¨è¦å®éªŒçš„æ¨¡å‹ï¼ˆä¾‹å¦‚ `DeepFM` æˆ– `DCN`ï¼‰ã€‚
    *   é€‰æ‹©åï¼Œä¸»ç•Œé¢ä¼šè‡ªåŠ¨åŠ è½½è¯¥æ¨¡å‹çš„é…ç½®æ–‡ä»¶ã€‚
    
    ### ç¬¬ä¸‰æ­¥ï¼šæ•°æ®é…ç½®
    æ‚¨æœ‰ä¸¤ç§æ–¹å¼é…ç½®æ•°æ®ï¼š
    1.  **å¿«é€Ÿè¦†ç›– (æ¨è)**ï¼šåœ¨ä¾§è¾¹æ å‹¾é€‰ `âœ… å¯ç”¨æ•°æ®é›†è¦†ç›–`ï¼Œç„¶åé€‰æ‹©ä¸€ä¸ªé¢„è®¾çš„æ•°æ®é›†ï¼ˆå¦‚ `tiny_csv`ï¼‰ã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆä¸´æ—¶çš„é…ç½®æ–‡ä»¶ã€‚
    2.  **æ‰‹åŠ¨é…ç½®**ï¼šåœ¨ä¸»ç•Œé¢çš„ `ğŸ› ï¸ é…ç½®ç®¡ç†` æ ‡ç­¾é¡µä¸­ï¼Œç›´æ¥ç¼–è¾‘ `dataset_config.yaml`ã€‚
    
    ### ç¬¬å››æ­¥ï¼šå¯åŠ¨ä»»åŠ¡
    åˆ‡æ¢åˆ° `â–¶ï¸ ä»»åŠ¡æ‰§è¡Œ` æ ‡ç­¾é¡µï¼š
    1.  è®¾ç½® **å®éªŒID** (Experiment ID)ã€‚
    2.  é€‰æ‹© **GPU è®¾å¤‡** (æˆ–ä½¿ç”¨ CPU)ã€‚
    3.  ç‚¹å‡» `ğŸ”¥ å¼€å§‹è®­ç»ƒ` æˆ– `ğŸ”® å¼€å§‹æ¨ç†`ã€‚
    
    ### ç¬¬äº”æ­¥ï¼šç›‘æ§ä¸åˆ†æ
    *   **å®æ—¶æ—¥å¿—**ï¼šä»»åŠ¡å¯åŠ¨åï¼Œä¸‹æ–¹ä¼šè‡ªåŠ¨æ˜¾ç¤ºè¿è¡Œæ—¥å¿—ã€‚
    *   **ä»»åŠ¡ç›‘æ§**ï¼šå±•å¼€ `ğŸ“¡ æœåŠ¡å™¨æ´»åŠ¨ä¸ä»»åŠ¡ç›‘æ§` é¢æ¿ï¼ŒæŸ¥çœ‹å½“å‰æœåŠ¡å™¨è´Ÿè½½å’Œæ‚¨çš„ä»»åŠ¡çŠ¶æ€ã€‚
    *   **å¯è§†åŒ–**ï¼šè®­ç»ƒå®Œæˆåï¼Œåˆ‡æ¢åˆ° `ğŸ“ˆ å¯è§†åŒ–` æ ‡ç­¾é¡µï¼Œä¸€é”®å¯åŠ¨ TensorBoard æŸ¥çœ‹ Loss å’Œ AUC æ›²çº¿ã€‚
    
    ---
    
    ## 3. æ ¸å¿ƒé…ç½®è¯¦è§£
    
    ### ğŸ›  dataset_config.yaml (æ•°æ®é…ç½®)
    æ­¤æ–‡ä»¶å®šä¹‰äº†æ•°æ®é›†çš„è·¯å¾„ã€æ ¼å¼å’Œç‰¹å¾å¤„ç†æ–¹å¼ã€‚
    
    ```yaml
    dataset_id:
        data_root: ../data/  # æ•°æ®æ ¹ç›®å½•
        data_format: csv     # æ•°æ®æ ¼å¼: csv, h5, parquet ç­‰
        train_data: ../data/train.csv
        valid_data: ../data/valid.csv
        test_data: ../data/test.csv
        min_categr_count: 1
        feature_cols:        # ç‰¹å¾å®šä¹‰åˆ—è¡¨
            - {name: user_id, active: True, dtype: str, type: categorical}
            - {name: item_id, active: True, dtype: str, type: categorical}
            - {name: age, active: True, dtype: float, type: numeric}
        label_col: {name: click, dtype: float}
    ```
    
    ### âš™ï¸ model_config.yaml (æ¨¡å‹é…ç½®)
    æ­¤æ–‡ä»¶å®šä¹‰äº†æ¨¡å‹çš„è¶…å‚æ•°ã€ä¼˜åŒ–å™¨å’Œè®­ç»ƒè®¾ç½®ã€‚
    
    ```yaml
    Base: # æ‰€æœ‰æ¨¡å‹çš„åŸºç±»é…ç½®
        model_root: './checkpoints/'
        workers: 3
        verbose: 1
        patience: 2
        pickle_feature_encoder: True
        use_hdf5: True
        save_best_only: True
        every_x_epochs: 1
        debug: False

    DeepFM_test: # ç‰¹å®šå®éªŒé…ç½®
        model: DeepFM
        dataset_id: tiny_csv # å…³è” dataset_config ä¸­çš„ ID
        loss: 'binary_crossentropy'
        metrics: ['logloss', 'AUC']
        task: binary_classification
        optimizer: adam
        learning_rate: 1.e-3
        embedding_regularizer: 1.e-8
        net_regularizer: 0
        batch_size: 128
        embedding_dim: 4
        epochs: 1
        shuffle: True
        seed: 2019
        monitor: 'AUC'
        monitor_mode: 'max'
    ```
    
    ## 4. å¸¸è§é—®é¢˜
    *   **Q: ä¸ºä»€ä¹ˆæ— æ³•å¯åŠ¨ä»»åŠ¡ï¼Ÿ**
        *   A: è¯·æ£€æŸ¥æ˜¯å¦å·²è¾“å…¥ç”¨æˆ·åï¼Œæˆ–è€…æ˜¯å¦å·²è¾¾åˆ°ä¸ªäºº/å…¨å±€ä»»åŠ¡æ•°é‡é™åˆ¶ã€‚
    *   **Q: å¦‚ä½•æŸ¥çœ‹å†å²æ—¥å¿—ï¼Ÿ**
        *   A: åœ¨ `ğŸ“Š æ¨¡å‹æƒé‡` æ ‡ç­¾é¡µä¸­ï¼Œé€‰æ‹©å¯¹åº”çš„æ•°æ®é›†ç›®å½•ï¼Œå¯ä»¥æŸ¥çœ‹å’Œé¢„è§ˆå†å²æ—¥å¿—æ–‡ä»¶ã€‚
    """)
    st.stop() # Stop execution here to show only tutorial

# Header
if st.session_state.show_tutorial:
    render_tutorial()

col_main, col_help = st.columns([6, 1])
with col_main:
    st.title("FuxiCTR å®éªŒå¹³å°")
with col_help:
    st.write("")
    if st.button("ğŸ“˜ ä½¿ç”¨æ•™ç¨‹"):
        st.session_state.show_tutorial = True
        st.rerun()

st.markdown("ä¸“ä¸šçš„ CTR æ¨¡å‹è®­ç»ƒä¸æ¨ç†å¹³å°")

st.markdown("---")

# Sidebar for Selection
with st.sidebar:
    st.header("ğŸ›ï¸ é¡¹ç›®è®¾ç½®")
    
    # User Identity for Task Management
    st.markdown("### ğŸ‘¤ ç”¨æˆ·èº«ä»½")
    
    # Initialize previous user reference for change detection
    if "prev_user" not in st.session_state:
        st.session_state.prev_user = "admin"

    # Define user list from provided images
    user_options = [
        "yeshao",
        "chenzeng2", "cywang50", "gjwang5", "gxwang9", 
        "hkhu3", "junzhang56", "mxsong", "qiancao6", 
        "taozhang48", "wenzhang33", "yangzhou23", "ymbo2"
    ]
    
    # Ensure prev_user is in options
    default_index = 0
    if st.session_state.prev_user in user_options:
        default_index = user_options.index(st.session_state.prev_user)

    current_user = st.selectbox("ç”¨æˆ·å", user_options, index=default_index, help="ç”¨äºä»»åŠ¡é™åˆ¶ï¼ˆæ¯ä½ç”¨æˆ·æœ€å¤š 1 ä¸ªä»»åŠ¡ï¼‰ã€‚")
    
    # Detect User Switch
    if current_user != st.session_state.prev_user:
        st.session_state.prev_user = current_user
        # Clear session state to prevent leaking previous user's task info
        st.session_state.run_pid = None
        st.session_state.run_logfile = None
        st.session_state.running_model = None
        st.rerun()

    if not current_user:
        st.warning("è¯·è¾“å…¥ç”¨æˆ·åã€‚")

    st.markdown("### ğŸ“ æ¨¡å‹é€‰æ‹©")
    models = get_models(MODEL_ZOO_DIR)
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", models, label_visibility="collapsed")
    if selected_model:
        st.caption(f"è·¯å¾„ï¼š`model_zoo/{selected_model}`")

    st.markdown("### ğŸ’¾ æ•°æ®é…ç½®")
    
    apply_override = st.checkbox("âœ… å¯ç”¨æ•°æ®é›†è¦†ç›–", value=False, help="è¦†ç›–æ¨¡å‹çš„é»˜è®¤æ•°æ®é›†é…ç½®ã€‚")
    
    if apply_override:
        datasets = get_subdirectories(DATA_DIR)
        
        # Calculate relative path dynamically based on model depth
        # Default depth is 1 (e.g. model_zoo/AutoInt) -> ../../data/
        # If depth is 2 (e.g. model_zoo/multitask/APG) -> ../../../data/
        model_depth = len(selected_model.split('/')) if selected_model else 1
        relative_data_path = "../" * (model_depth + 1) + "data/"

        def update_dataset_fields():
            if st.session_state.dataset_template:
                d = st.session_state.dataset_template
                st.session_state.ds_id_val = d
                path = os.path.join(relative_data_path, d)
                st.session_state.ds_train_val = path
                st.session_state.ds_valid_val = path
                st.session_state.ds_test_val = path
                st.session_state.ds_infer_val = path
                st.session_state.ds_root_val = relative_data_path

        st.selectbox(
            "å¿«é€ŸåŠ è½½æ•°æ®é›†æ¨¡æ¿ (å¯é€‰)", 
            datasets, 
            index=None,
            key="dataset_template",
            on_change=update_dataset_fields,
            placeholder="é€‰æ‹©ä»¥è‡ªåŠ¨å¡«å……è·¯å¾„..."
        )
        
        with st.expander("âš™ï¸ è¯¦ç»†è®¾ç½®", expanded=True):
            # Initialize session state if not present
            if "ds_id_val" not in st.session_state: st.session_state.ds_id_val = ""
            if "ds_root_val" not in st.session_state: st.session_state.ds_root_val = relative_data_path
            if "ds_train_val" not in st.session_state: st.session_state.ds_train_val = ""
            if "ds_valid_val" not in st.session_state: st.session_state.ds_valid_val = ""
            if "ds_test_val" not in st.session_state: st.session_state.ds_test_val = ""
            if "ds_infer_val" not in st.session_state: st.session_state.ds_infer_val = ""
            if "ds_split_val" not in st.session_state: st.session_state.ds_split_val = "random"

            st.text_input("Dataset ID", key="ds_id_val", help="æ•°æ®é›†çš„å”¯ä¸€æ ‡è¯†ç¬¦ (å¯æ‰‹åŠ¨è¾“å…¥)")
            st.text_input("Data Root", key="ds_root_val", help="æ•°æ®æ ¹ç›®å½•è·¯å¾„ (æ”¯æŒç»å¯¹è·¯å¾„)")
            st.text_input("Train Data", key="ds_train_val", help="è®­ç»ƒæ•°æ®æ–‡ä»¶è·¯å¾„")
            st.text_input("Valid Data", key="ds_valid_val", help="éªŒè¯æ•°æ®æ–‡ä»¶è·¯å¾„")
            st.text_input("Test Data", key="ds_test_val", help="æµ‹è¯•æ•°æ®æ–‡ä»¶è·¯å¾„")
            st.text_input("Infer Data", key="ds_infer_val", help="æ¨ç†æ•°æ®æ–‡ä»¶è·¯å¾„ (å¯é€‰ï¼Œç•™ç©ºåˆ™å¿½ç•¥)")
            st.selectbox("Split Type", ["random", "sequential"], key="ds_split_val", help="æ•°æ®åˆ‡åˆ†æ–¹å¼")

if selected_model:
    model_path = os.path.join(MODEL_ZOO_DIR, selected_model)
    
    # Get isolated config paths
    config_info, user_config_save_dir = get_config_paths(selected_model, current_user)
    
    dataset_config_path = config_info["dataset_config.yaml"]["path"]
    model_config_path = config_info["model_config.yaml"]["path"]
    run_expid_path = config_info["run_expid.py"]["path"]
    
    # Tabs with Icons
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ› ï¸ é…ç½®ç®¡ç†", "â–¶ï¸ ä»»åŠ¡æ‰§è¡Œ", "ğŸ“Š æ¨¡å‹æƒé‡", "ğŸ“ˆ å¯è§†åŒ–"])

    with tab1:
        st.markdown("### ğŸ“ é…ç½®ç¼–è¾‘å™¨")
        
        # Check if any custom config is active
        has_custom = any(config_info[k]["type"] == "custom" for k in config_info)
        if has_custom:
            st.info(f"ğŸ’¡ å½“å‰æ­£åœ¨ç¼–è¾‘ **{current_user}** çš„è‡ªå®šä¹‰é…ç½®ã€‚")
        else:
            st.info("ğŸ’¡ å½“å‰æ˜¾ç¤ºçš„æ˜¯ç³»ç»Ÿé»˜è®¤é…ç½®ã€‚ä¿å­˜ä¿®æ”¹åå°†è‡ªåŠ¨åˆ›å»ºæ‚¨çš„ä¸ªäººå‰¯æœ¬ã€‚")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Dataset Config Section
            ds_info = config_info["dataset_config.yaml"]
            is_custom_ds = ds_info["type"] == "custom"
            
            header_cols = st.columns([3, 1, 1])
            with header_cols[0]:
                st.markdown("### dataset_config.yaml")
            with header_cols[1]:
                st.download_button(
                    label="â¬‡ï¸ å¯¼å‡º",
                    data=load_file_content(dataset_config_path),
                    file_name="dataset_config.yaml",
                    mime="application/x-yaml",
                    key=f"dl_ds_{selected_model}"
                )
            with header_cols[2]:
                if is_custom_ds:
                    if st.button("ğŸ”„ é‡ç½®", key=f"reset_ds_{selected_model}", help="åˆ é™¤è‡ªå®šä¹‰é…ç½®ï¼Œæ¢å¤ç³»ç»Ÿé»˜è®¤"):
                        reset_user_config(current_user, selected_model, "dataset_config.yaml")
                        st.rerun()
            
            if is_custom_ds:
                st.caption("âœ… ä½¿ç”¨ä¸­ï¼šä¸ªäººè‡ªå®šä¹‰é…ç½®")
            else:
                st.caption("ğŸ”’ ä½¿ç”¨ä¸­ï¼šç³»ç»Ÿé»˜è®¤é…ç½®")

            with st.expander("ğŸ“‚ ä¸Šä¼  / æ›¿æ¢æ–‡ä»¶"):
                uploaded_dataset = st.file_uploader("ä¸Šä¼  dataset_config.yaml", type=["yaml", "yml"], key=f"dataset_uploader_{selected_model}")
                if uploaded_dataset is not None:
                    content = uploaded_dataset.read().decode("utf-8")
                    # Always save to user config dir
                    save_path = os.path.join(user_config_save_dir, "dataset_config.yaml")
                    save_file_content(save_path, content)
                    st.success("å·²ä¿å­˜åˆ°ä¸ªäººé…ç½®ï¼")
                    st.rerun()
            
            dataset_content = load_file_content(dataset_config_path)
            new_dataset_content = st.text_area("å†…å®¹", dataset_content, height=400, key=f"dataset_editor_{selected_model}", label_visibility="collapsed")
            
        with col2:
            # Model Config Section
            md_info = config_info["model_config.yaml"]
            is_custom_md = md_info["type"] == "custom"
            
            header_cols_m = st.columns([3, 1, 1])
            with header_cols_m[0]:
                st.markdown("### model_config.yaml")
            with header_cols_m[1]:
                st.download_button(
                    label="â¬‡ï¸ å¯¼å‡º",
                    data=load_file_content(model_config_path),
                    file_name="model_config.yaml",
                    mime="application/x-yaml",
                    key=f"dl_md_{selected_model}"
                )
            with header_cols_m[2]:
                if is_custom_md:
                    if st.button("ğŸ”„ é‡ç½®", key=f"reset_md_{selected_model}", help="åˆ é™¤è‡ªå®šä¹‰é…ç½®ï¼Œæ¢å¤ç³»ç»Ÿé»˜è®¤"):
                        reset_user_config(current_user, selected_model, "model_config.yaml")
                        st.rerun()

            if is_custom_md:
                st.caption("âœ… ä½¿ç”¨ä¸­ï¼šä¸ªäººè‡ªå®šä¹‰é…ç½®")
            else:
                st.caption("ğŸ”’ ä½¿ç”¨ä¸­ï¼šç³»ç»Ÿé»˜è®¤é…ç½®")
            
            with st.expander("ğŸ“‚ ä¸Šä¼  / æ›¿æ¢æ–‡ä»¶"):
                uploaded_model = st.file_uploader("ä¸Šä¼  model_config.yaml", type=["yaml", "yml"], key=f"model_uploader_{selected_model}")
                if uploaded_model is not None:
                    content = uploaded_model.read().decode("utf-8")
                    # Always save to user config dir
                    save_path = os.path.join(user_config_save_dir, "model_config.yaml")
                    save_file_content(save_path, content)
            model_content = load_file_content(model_config_path)
            new_model_content = st.text_area("å†…å®¹", model_content, height=400, key=f"model_editor_{selected_model}", label_visibility="collapsed")

        st.markdown("---")
        
        # Run Script Config Section
        script_info = config_info["run_expid.py"]
        is_custom_script = script_info["type"] == "custom"
        
        header_cols_s = st.columns([3, 1, 1])
        with header_cols_s[0]:
            st.markdown("### ğŸ“œ run_expid.py")
        with header_cols_s[1]:
            st.download_button(
                label="â¬‡ï¸ å¯¼å‡º",
                data=load_file_content(run_expid_path),
                file_name="run_expid.py",
                mime="text/x-python",
                key=f"dl_script_{selected_model}"
            )
        with header_cols_s[2]:
            if is_custom_script:
                if st.button("ğŸ”„ é‡ç½®", key=f"reset_script_{selected_model}", help="åˆ é™¤è‡ªå®šä¹‰è„šæœ¬ï¼Œæ¢å¤ç³»ç»Ÿé»˜è®¤"):
                    reset_user_config(current_user, selected_model, "run_expid.py")
                    st.rerun()
        
        if is_custom_script:
            st.caption("âœ… ä½¿ç”¨ä¸­ï¼šä¸ªäººè‡ªå®šä¹‰è„šæœ¬")
        else:
            st.caption("ğŸ”’ ä½¿ç”¨ä¸­ï¼šç³»ç»Ÿé»˜è®¤è„šæœ¬")

        with st.expander("ğŸ“‚ ä¸Šä¼  / æ›¿æ¢è„šæœ¬"):
            uploaded_script = st.file_uploader("ä¸Šä¼  run_expid.py", type=["py"], key=f"script_uploader_{selected_model}")
            if uploaded_script is not None:
                content = uploaded_script.read().decode("utf-8")
                save_path = os.path.join(user_config_save_dir, "run_expid.py")
                save_file_content(save_path, content)
                st.success("è„šæœ¬å·²æ›´æ–°åˆ°ä¸ªäººé…ç½®ï¼")
                st.rerun()

        run_expid_content = load_file_content(run_expid_path)
        new_run_expid_content = st.text_area("å†…å®¹", run_expid_content, height=300, key=f"script_editor_{selected_model}", label_visibility="collapsed")

        if st.button("ğŸ’¾ ä¿å­˜æ‰€æœ‰é…ç½®", type="primary"):
            # Save configs to user directory
            save_file_content(os.path.join(user_config_save_dir, "dataset_config.yaml"), new_dataset_content)
            save_file_content(os.path.join(user_config_save_dir, "model_config.yaml"), new_model_content)
            save_file_content(os.path.join(user_config_save_dir, "run_expid.py"), new_run_expid_content)
            
            st.toast("é…ç½®å·²ä¿å­˜åˆ°æ‚¨çš„ä¸ªäººç©ºé—´ï¼", icon="âœ…")
            time.sleep(1)
            st.rerun()

    with tab2:
        st.markdown("### ğŸš€ å®éªŒæ§åˆ¶")
        
        # --- Task State Restoration & Limits Check ---
        active_tasks = get_active_tasks()
        global_task_count = len(active_tasks)
        user_tasks = [t for t in active_tasks if t['username'] == current_user]
        user_task_count = len(user_tasks)
        
        # Restore state if user has a running task but session is empty
        if st.session_state.run_pid is None and user_task_count > 0:
            # Restore the first found task for this user
            task = user_tasks[0]
            st.session_state.run_pid = task['pid']
            st.session_state.run_logfile = task['logfile']
            st.session_state.running_model = task['model']
            st.toast(f"å·²æ¢å¤ä»»åŠ¡ä¼šè¯ PID: {task['pid']}", icon="ğŸ”„")

        # --- Task Monitor Dashboard ---
        with st.expander("ğŸ“¡ æœåŠ¡å™¨æ´»åŠ¨ä¸ä»»åŠ¡ç›‘æ§", expanded=True):
            col_m1, col_m2, col_m3 = st.columns([1, 1, 2])
            
            with col_m1:
                st.metric("å…¨å±€è´Ÿè½½", f"{global_task_count} / 3", help="æœåŠ¡å™¨ä¸Šçš„æ€»æ´»è·ƒä»»åŠ¡æ•°")
            
            with col_m2:
                delta_color = "normal" if user_task_count == 0 else "off"
                st.metric("æ‚¨çš„é…é¢", f"{user_task_count} / 1", "æ´»è·ƒä»»åŠ¡", delta_color=delta_color, help="æ‚¨åŒæ—¶æœ€å¤šåªèƒ½è¿è¡Œ 1 ä¸ªä»»åŠ¡")
            
            with col_m3:
                if active_tasks:
                    task_data = []
                    for t in active_tasks:
                        duration = int(time.time() - t['start_time'])
                        mins, secs = divmod(duration, 60)
                        hours, mins = divmod(mins, 60)
                        dur_str = f"{hours}h {mins}m" if hours > 0 else f"{mins}m {secs}s"
                        task_data.append({
                            "ç”¨æˆ·": t['username'],
                            "æ¨¡å‹": t['model'],
                            "PID": t['pid'],
                            "è¿è¡Œæ—¶é•¿": dur_str
                        })
                    st.dataframe(task_data, hide_index=True, use_container_width=True)
                else:
                    st.info("æš‚æ— æ´»è·ƒä»»åŠ¡")
                            
        def start_process(command, log_filename, model_name, config_override_path=None):
            log_path = os.path.join(LOG_DIR, log_filename)
            f = open(log_path, "w")
            
            final_cmd = command
            
            # Logic for Config Injection
            if config_override_path:
                final_cmd = f"{command} --config {config_override_path}"
            elif any(config_info[k]["type"] == "custom" for k in ["dataset_config.yaml", "model_config.yaml"]):
                # Use user config directory
                final_cmd = f"{command} --config {user_config_save_dir}"
            
            # Logic for Script Injection (run_expid.py)
            # If user has custom script, we need to run that instead of the default one.
            # To ensure imports work, we copy it to the model directory with a unique name.
            script_info = config_info["run_expid.py"]
            if script_info["type"] == "custom":
                custom_script_name = f"run_expid_{current_user}.py"
                custom_script_path = os.path.join(model_path, custom_script_name)
                shutil.copy(script_info["path"], custom_script_path)
                # Replace run_expid.py in the command with the custom script name
                final_cmd = final_cmd.replace("run_expid.py", custom_script_name)
            
            # Use start_new_session=True to create a process group, so we can kill the whole tree later
            p = subprocess.Popen(final_cmd, shell=True, stdout=f, stderr=subprocess.STDOUT, start_new_session=True)
            f.close()
            
            # Update Session State
            st.session_state.run_pid = p.pid
            st.session_state.run_logfile = log_path
            st.session_state.running_model = model_name
            
            # Register Task Globally
            save_task_state(current_user, p.pid, model_name, log_path)
            
        def stop_process():
            if st.session_state.run_pid:
                try:
                    # Kill the process group to ensure child processes (like the python script) are also killed
                    # Since start_new_session=True was used, the PID is the PGID.
                    # We use SIGKILL (9) to ensure it stops, and avoid os.getpgid lookup which fails if parent is dead.
                    os.killpg(st.session_state.run_pid, signal.SIGKILL)
                except Exception:
                    pass
                
                # Unregister Task Globally
                remove_task_state(st.session_state.run_pid)
                
                st.session_state.run_pid = None
                st.session_state.running_model = None

        # Experiment Parameters
        col_p1, col_p2 = st.columns(2)
        with col_p1:
            expid = st.text_input("Experiment ID", value=selected_model.split('/')[-1] + "_test" if selected_model else "test", help="å¯¹åº” model_config.yaml ä¸­çš„ experiment_id")
        with col_p2:
            gpu = st.selectbox("GPU Device", options=[0, 1, 2, 3, 4, 5, 6, 7], index=0, help="é€‰æ‹©ä½¿ç”¨çš„ GPU è®¾å¤‡ ID")

        st.markdown("#### æ“ä½œ")
        
        col_train, col_infer, col_stop = st.columns(3)
        
        # Check if current selected model matches the running model
        is_running_other_model = st.session_state.run_pid is not None and st.session_state.running_model != selected_model
        
        if is_running_other_model:
            st.warning(f"âš ï¸ å¦ä¸€ä¸ªæ¨¡å‹ (**{st.session_state.running_model}**) æ­£åœ¨è¿è¡Œã€‚è¯·åœ¨å¼€å§‹æ–°ä»»åŠ¡å‰åœæ­¢å®ƒã€‚")

        # Limit Checks
        can_start = True
        limit_msg = ""
        if not current_user:
            can_start = False
            limit_msg = "éœ€è¦ç”¨æˆ·åã€‚"
        elif st.session_state.run_pid is not None:
            can_start = False # Already running in this session
        elif user_task_count >= 1:
            can_start = False
            limit_msg = f"è¾¾åˆ°ç”¨æˆ·é™åˆ¶ ({user_task_count}/1)ã€‚"
        elif global_task_count >= 3:
            can_start = False
            limit_msg = f"è¾¾åˆ°å…¨å±€é™åˆ¶ ({global_task_count}/3)ã€‚"

        if col_train.button("ğŸ”¥ å¼€å§‹è®­ç»ƒ", type="primary", disabled=not can_start):
            if not can_start and limit_msg:
                st.error(limit_msg)
            else:
                config_override_dir = None
            
            # Extract dataset params from session state
            ds_id = st.session_state.get("ds_id_val", "custom_dataset")
            ds_root = st.session_state.get("ds_root_val", "")
            ds_train = st.session_state.get("ds_train_val", "")
            ds_valid = st.session_state.get("ds_valid_val", "")
            ds_test = st.session_state.get("ds_test_val", "")
            ds_infer = st.session_state.get("ds_infer_val", "")
            ds_split = st.session_state.get("ds_split_val", "random")
            ds_train_size = 0.8
            ds_valid_size = 0.1
            ds_test_size = 0.1

            if apply_override:
                # Generate temporary config override
                timestamp = int(time.time())
                temp_config_dir = os.path.join(LOG_DIR, "configs", f"{expid}_{timestamp}")
                os.makedirs(temp_config_dir, exist_ok=True)
                
                # 1. Load and Modify Model Config
                try:
                    with open(model_config_path, 'r') as f:
                        model_conf = yaml.safe_load(f)
                    
                    # Get original dataset_id from the target experiment
                    original_ds_id = None
                    if expid in model_conf:
                        original_ds_id = model_conf[expid].get('dataset_id')
                    
                    # Update dataset_id in ALL sections (including template)
                    for key in model_conf:
                        if isinstance(model_conf[key], dict) and 'dataset_id' in model_conf[key]:
                             model_conf[key]['dataset_id'] = ds_id
                    
                    with open(os.path.join(temp_config_dir, "model_config.yaml"), 'w') as f:
                        yaml.dump(model_conf, f)
                        
                    # 2. Generate Dataset Config
                    # Try to load existing dataset config to preserve feature_cols and label_col
                    existing_ds_conf = {}
                    try:
                        with open(dataset_config_path, 'r') as f:
                            existing_ds_conf = yaml.safe_load(f) or {}
                    except:
                        pass

                    ds_params = {
                        'data_root': ds_root,
                        'data_format': 'parquet',
                        'train_data': ds_train,
                        'valid_data': ds_valid,
                        'test_data': ds_test,
                        'split_type': ds_split,
                        'train_size': ds_train_size,
                        'valid_size': ds_valid_size,
                        'test_size': ds_test_size
                    }
                    
                    # Copy schema from existing config using ORIGINAL ID
                    if original_ds_id and original_ds_id in existing_ds_conf:
                        if 'feature_cols' in existing_ds_conf[original_ds_id]:
                            ds_params['feature_cols'] = existing_ds_conf[original_ds_id]['feature_cols']
                        if 'label_col' in existing_ds_conf[original_ds_id]:
                            ds_params['label_col'] = existing_ds_conf[original_ds_id]['label_col']
                    
                    # Remove empty fields to avoid "Invalid data path: *.parquet" error
                    # FuxiCTR will try to glob "*.parquet" if the path is empty, which fails.
                    if not ds_valid:
                        ds_params.pop('valid_data', None)
                    if not ds_test:
                        ds_params.pop('test_data', None)
                    
                    if ds_infer:
                        ds_params['infer_data'] = ds_infer
                        
                    dataset_conf = {
                        ds_id: ds_params
                    }
                    with open(os.path.join(temp_config_dir, "dataset_config.yaml"), 'w') as f:
                        yaml.dump(dataset_conf, f)
                        
                    config_override_dir = temp_config_dir
                    st.toast(f"ä½¿ç”¨æ•°æ®é›†è¦†ç›–ï¼š{ds_id} (ç»§æ‰¿è‡ª {original_ds_id})", icon="âš™ï¸")
                    
                except Exception as e:
                    st.error(f"ç”Ÿæˆé…ç½®è¦†ç›–å¤±è´¥ï¼š{e}")
                    st.stop()

            cmd = f"cd {model_path} && python run_expid.py --expid {expid} --gpu {gpu} --mode train"
            # Include username in log filename for isolation
            start_process(cmd, f"{expid}_{current_user}_train.log", selected_model, config_override_dir)
            st.rerun()

        if col_infer.button("ğŸ”® å¼€å§‹æ¨ç†", disabled=not can_start):
            if not can_start and limit_msg:
                st.error(limit_msg)
            else:
                # Inference also needs the config override if we want to use the same data settings
                config_override_dir = None
            
            # Extract dataset params from session state
            ds_id = st.session_state.get("ds_id_val", "custom_dataset")
            ds_root = st.session_state.get("ds_root_val", "")
            ds_train = st.session_state.get("ds_train_val", "")
            ds_valid = st.session_state.get("ds_valid_val", "")
            ds_test = st.session_state.get("ds_test_val", "")
            ds_infer = st.session_state.get("ds_infer_val", "")
            ds_split = st.session_state.get("ds_split_val", "random")
            ds_train_size = 0.8
            ds_valid_size = 0.1
            ds_test_size = 0.1

            if apply_override:
                 # Generate temporary config override (Same logic as training)
                timestamp = int(time.time())
                temp_config_dir = os.path.join(LOG_DIR, "configs", f"{expid}_infer_{timestamp}")
                os.makedirs(temp_config_dir, exist_ok=True)
                
                try:
                    with open(model_config_path, 'r') as f:
                        model_conf = yaml.safe_load(f)
                    
                    # Get original dataset_id from the target experiment
                    original_ds_id = None
                    if expid in model_conf:
                        original_ds_id = model_conf[expid].get('dataset_id')
                    
                    # Update dataset_id in ALL sections (including template)
                    for key in model_conf:
                        if isinstance(model_conf[key], dict) and 'dataset_id' in model_conf[key]:
                             model_conf[key]['dataset_id'] = ds_id
                    
                    with open(os.path.join(temp_config_dir, "model_config.yaml"), 'w') as f:
                        yaml.dump(model_conf, f)
                    
                    # Try to load existing dataset config to preserve feature_cols and label_col
                    existing_ds_conf = {}
                    try:
                        with open(dataset_config_path, 'r') as f:
                            existing_ds_conf = yaml.safe_load(f) or {}
                    except:
                        pass

                    ds_params = {
                        'data_root': ds_root,
                        'data_format': 'parquet',
                        'train_data': ds_train,
                        'valid_data': ds_valid,
                        'test_data': ds_test,
                        'split_type': ds_split,
                        'train_size': ds_train_size,
                        'valid_size': ds_valid_size,
                        'test_size': ds_test_size
                    }

                    # Copy schema from existing config using ORIGINAL ID
                    if original_ds_id and original_ds_id in existing_ds_conf:
                        if 'feature_cols' in existing_ds_conf[original_ds_id]:
                            ds_params['feature_cols'] = existing_ds_conf[original_ds_id]['feature_cols']
                        if 'label_col' in existing_ds_conf[original_ds_id]:
                            ds_params['label_col'] = existing_ds_conf[original_ds_id]['label_col']

                    if not ds_valid:
                        ds_params.pop('valid_data', None)
                    if not ds_test:
                        ds_params.pop('test_data', None)
                    if ds_infer:
                        ds_params['infer_data'] = ds_infer

                    dataset_conf = {
                        ds_id: ds_params
                    }
                    with open(os.path.join(temp_config_dir, "dataset_config.yaml"), 'w') as f:
                        yaml.dump(dataset_conf, f)
                    config_override_dir = temp_config_dir
                except Exception as e:
                    st.error(f"ç”Ÿæˆé…ç½®è¦†ç›–å¤±è´¥ï¼š{e}")
                    st.stop()

            cmd = f"cd {model_path} && python run_expid.py --expid {expid} --gpu {gpu} --mode inference"
            # Include username in log filename for isolation
            start_process(cmd, f"{expid}_{current_user}_inference.log", selected_model, config_override_dir)
            st.rerun()
            
        if col_stop.button("ğŸ›‘ åœæ­¢è¿›ç¨‹", type="secondary", disabled=st.session_state.run_pid is None):
            stop_process()
            st.rerun()

        # Status & Logs Monitoring
        st.markdown("---")
        
        is_running = False
        if st.session_state.run_pid:
            try:
                # Try to wait for the process to check if it's a zombie (finished but not reaped)
                # os.WNOHANG ensures we don't block if it's still running
                pid, status = os.waitpid(st.session_state.run_pid, os.WNOHANG)
                if pid == 0:
                    # Process is still running
                    is_running = True
                else:
                    # Process exited and was reaped
                    is_running = False
            except ChildProcessError:
                # Not a child of this process (e.g. restored from session state after restart)
                # Fallback to os.kill check
                try:
                    os.kill(st.session_state.run_pid, 0)
                    is_running = True
                except OSError:
                    is_running = False
            except OSError:
                is_running = False

            if is_running:
                if st.session_state.running_model == selected_model:
                    st.success(f"ğŸŸ¢ **è¿è¡Œä¸­** (PID: {st.session_state.run_pid}) | ç”¨æˆ·: {current_user}")
                else:
                    st.info(f"åå°è¿è¡Œä¸­ï¼š**{st.session_state.running_model}**")
            else:
                # Cleanup if process finished
                remove_task_state(st.session_state.run_pid)
                st.session_state.run_pid = None
                st.session_state.running_model = None
                st.info("âœ… **å·²å®Œæˆ**")
                st.rerun()
        else:
            st.info("âšª **ç©ºé—²**")

        # Only show logs if the selected model is the one running
        if st.session_state.running_model == selected_model or st.session_state.running_model is None:
            st.subheader("ğŸ“‹ å®æ—¶æ—¥å¿—")
            
            # Auto-refresh toggle
            auto_refresh = st.checkbox("ğŸ”„ è‡ªåŠ¨åˆ·æ–°æ—¥å¿—", value=True, help="å–æ¶ˆå‹¾é€‰ä»¥åœæ­¢é¡µé¢åˆ·æ–°ï¼ˆæŸ¥çœ‹ TensorBoard æ—¶å¾ˆæœ‰ç”¨ï¼‰")

            if st.session_state.run_logfile and os.path.exists(st.session_state.run_logfile):
                with open(st.session_state.run_logfile, "r") as f:
                    lines = f.readlines()
                    if lines:
                        st.code("".join(lines[-50:]), language="text")
                    else:
                        st.caption("ç­‰å¾…æ—¥å¿—...")
            else:
                st.caption("æš‚æ— æ—¥å¿—ã€‚")
            
            if is_running and auto_refresh:
                time.sleep(2)
                st.rerun()
        else:
            st.caption(f"**{st.session_state.running_model}** çš„æ—¥å¿—å·²éšè—ã€‚åˆ‡æ¢å›è¯¥æ¨¡å‹ä»¥æŸ¥çœ‹å®æ—¶æ—¥å¿—ã€‚")

    with tab3:
        st.markdown("### ğŸ“‚ æƒé‡ä¸æ–‡ä»¶")
        checkpoint_dir = os.path.join(model_path, "checkpoints")
        
        if os.path.exists(checkpoint_dir):
            dataset_dirs = get_subdirectories(checkpoint_dir)
            
            if dataset_dirs:
                selected_dataset_dir = st.selectbox("é€‰æ‹©æ•°æ®é›†ç›®å½•", dataset_dirs)
                
                if selected_dataset_dir:
                    target_dir = os.path.join(checkpoint_dir, selected_dataset_dir)
                    files = os.listdir(target_dir)
                    
                    # Dataframe for files
                    file_data = []
                    log_files = []
                    for f in files:
                        fp = os.path.join(target_dir, f)
                        stat = os.stat(fp)
                        size_mb = stat.st_size / (1024 * 1024)
                        mod_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(stat.st_mtime))
                        file_data.append({"æ–‡ä»¶å": f, "å¤§å° (MB)": f"{size_mb:.2f}", "æœ€åä¿®æ”¹æ—¶é—´": mod_time})
                        if f.endswith(".log"):
                            log_files.append(f)
                    
                    df = pd.DataFrame(file_data)
                    st.dataframe(df, use_container_width=True)

                    # Log Preview Section
                    if log_files:
                        st.markdown("---")
                        st.subheader("ğŸ“œ æ—¥å¿—æŸ¥çœ‹å™¨")
                        selected_log = st.selectbox("é€‰æ‹©æ—¥å¿—æ–‡ä»¶", log_files)
                        if selected_log:
                            log_path = os.path.join(target_dir, selected_log)
                            with open(log_path, "r") as f:
                                st.code(f.read(), language="text")
            else:
                st.warning("åœ¨ checkpoints ä¸­æœªæ‰¾åˆ°æ•°æ®é›†ç›®å½•ã€‚")
        else:
            st.warning("å°šæœªæ‰¾åˆ° checkpoints ç›®å½•ã€‚è¯·å…ˆè¿è¡Œè®­ç»ƒä»»åŠ¡ã€‚")

    with tab4:
        st.header("ğŸ“ˆ TensorBoard å¯è§†åŒ–")
        checkpoint_dir = os.path.join(model_path, "checkpoints")
        
        if os.path.exists(checkpoint_dir):
            st.markdown('<div class="css-1r6slb0">', unsafe_allow_html=True)
            
            st.subheader("ğŸ”Œ è¿æ¥ä¿¡æ¯")
            st.caption("æ—¥å¿—ç›®å½•æºï¼š")
            st.code(checkpoint_dir, language="bash")
            
            st.markdown("---")
            
            col_launch, col_open = st.columns(2)
            
            with col_launch:
                if st.button("ğŸš€ å¯åŠ¨æœåŠ¡ (ç«¯å£ 6006)", type="primary", use_container_width=True):
                    cmd = f"tensorboard --logdir {checkpoint_dir} --port 6006"
                    subprocess.Popen(cmd, shell=True)
                    st.toast("TensorBoard æœåŠ¡å·²å¯åŠ¨ï¼", icon="âœ…")
                    time.sleep(1)
            
            with col_open:
                st.markdown(
                    """
                    <a href="http://localhost:6006" target="_blank" style="text-decoration: none;">
                        <div style="
                            display: flex;
                            justify-content: center;
                            align-items: center;
                            width: 100%;
                            background-color: #EFF6FF;
                            border: 1px solid #BFDBFE;
                            color: #1E40AF;
                            padding: 0.55rem;
                            border-radius: 8px;
                            font-weight: 600;
                            text-decoration: none;
                            transition: all 0.2s;
                        ">
                            ğŸ”— æ‰“å¼€ç•Œé¢
                        </div>
                    </a>
                    """,
                    unsafe_allow_html=True
                )

            st.markdown("</div>", unsafe_allow_html=True)
            
            st.markdown("### ğŸ’¡ å¿«é€ŸæŒ‡å—")
            st.markdown("""
            - **ç¬¬ä¸€æ­¥**ï¼šç‚¹å‡» **å¯åŠ¨æœåŠ¡** ä»¥å¼€å¯åå°è¿›ç¨‹ã€‚
            - **ç¬¬äºŒæ­¥**ï¼šç‚¹å‡» **æ‰“å¼€ç•Œé¢** ä»¥æŸ¥çœ‹æŒ‡æ ‡ã€‚
            - **æ³¨æ„**ï¼šå¦‚æœåˆ‡æ¢æ¨¡å‹ï¼Œæ‚¨å¯èƒ½éœ€è¦é‡å¯æœåŠ¡æˆ–åˆ·æ–° TensorBoardã€‚
            """)
        else:
            st.warning("âš ï¸ æœªæ‰¾åˆ° checkpoints ç›®å½•ã€‚è¯·å…ˆè¿è¡Œè®­ç»ƒä»»åŠ¡ã€‚")
